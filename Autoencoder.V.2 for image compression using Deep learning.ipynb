{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2\n",
    "# Autoencoder for image compression using Deep learning\n",
    "\n",
    "<img src=\"https://www.oscprofessionals.com/wp-content/uploads/2019/11/lossless-compression-banner-2.jpg\" height=\"100px\" width=\"100%\">\n",
    "\n",
    "### By Tirtharaj Sinha([@tirtharajsinha](https://github.com/tirtharajsinha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to subpress warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    #importing librarys\n",
    "\n",
    "    # cv2 is a python external package to do image processing and manipulation related stuff.\n",
    "    import cv2 \n",
    "\n",
    "    # imutils is a series of convenience functions to make basic image processing easy.\n",
    "    import imutils\n",
    "\n",
    "    # tensorflow is a python library for machine learning and artificial intelligence related work.\n",
    "    import tensorflow as tf \n",
    "\n",
    "\n",
    "    # NumPy is a Python library used for working with arrays\n",
    "    import numpy as np\n",
    "    \n",
    "    # pandas offers data structures and operations for manipulating numerical tables and time series.\n",
    "    import pandas as pd\n",
    "\n",
    "    # Keras is a library that provides a Python interface for artificial neural networks. \n",
    "    # Keras acts as an interface for the TensorFlow library.\n",
    "    import keras\n",
    "\n",
    "\n",
    "    # 1. Keras layers are the building blocks of the Keras library that can be stacked together for creating neural network models.\n",
    "    # 2. Keras Conv2D creates a 2D convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
    "    # 3. maxpooling2D Downsamples the input along its spatial dimensions by taking the maximum value over an input window for each channel of the input. \n",
    "    # 4 .Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. \n",
    "    # 5 .Dropout regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data.\n",
    "    # 6. Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. \n",
    "    from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "    #  Model groups layers into an object with training and inference features.\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    # tensorflow.keras.callbacks is used to visualize training of a model.\n",
    "    from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint \n",
    "\n",
    "    # used to split dataset(features and target) into test and test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # F1/F Score is a measure of how accurate a model is by using Precision and Recall following the \n",
    "    # formula of: F1_Score = 2 * ((Precision * Recall) / (Precision + Recall)) \n",
    "    # Precision is commonly called positive predictive value.\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    # shuffle the dataset for a even mixture of each type of feature and target.it gives better result.\n",
    "    from sklearn.utils import shuffle\n",
    "\n",
    "    # A one hot encoding allows the representation of categorical data to be more expressive.\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    # confusion matrix is used to evaluate the accuracy of a classification.[[TP,FP],[FN,TN]]\n",
    "    # A classification report is a performance evaluation metric in machine learning. \n",
    "    # It is used to show the precision, recall, F1 Score, and support of your trained classification model.\n",
    "    from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "    # importing prebuild structure similarity index \n",
    "    from skimage.metrics import structural_similarity as SSIM\n",
    "    \n",
    "    # The OS module in Python provides functions for interacting with the operating system.\n",
    "    import os\n",
    "\n",
    "    # Matplotlib is a data visualization and graphical plotting library for Python.\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # seaborn is alse a data visualization and graphical plotting library for Python.\n",
    "    import seaborn as sn\n",
    "\n",
    "    # used to display markdown,image,control (frontend utilities)\n",
    "    from IPython import display\n",
    "\n",
    "    import time\n",
    "    # time package\n",
    "    \n",
    "    from math import log10, sqrt\n",
    "    # for mathematical operations\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    \n",
    "except:\n",
    "    !pip install -r requirements.txt\n",
    "# dataset path \n",
    "path = r\"DATASET\"\n",
    "# make sure in this dir two folder named \"yes\" and \"no\" is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Info \n",
    "try:\n",
    "    import GPUtil\n",
    "except:\n",
    "    !pip install GPUtil\n",
    "    import GPUtil\n",
    "\n",
    "    \n",
    "# check physical computing devices\n",
    "device=tf.config.experimental.list_physical_devices()\n",
    "for i in device:\n",
    "    print(i)\n",
    "if len(device)>1:\n",
    "    # find GPU details\n",
    "    print(\"=\"*20, \"GPU Details\", \"=\"*20)\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        print(gpu_id,gpu.name, gpu.driver,gpu.memoryTotal,gpu.temperature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function crop out the unnecessary part of a image.\n",
    "# it takes two parameter -> image : numpy/cv2 image array , plot : binary (You want to plot after before effect of the image)\n",
    "\n",
    "\n",
    "def image_threshholder(image, plot=False):\n",
    "    # grayscalling the image\n",
    "    # applying gausionBlur operation on grayscaled image.\n",
    "    # binary threshholding the image to clean the gray scale range and makes the image binary colored based on range.\n",
    "    # to remove thresh holding comment the next line\n",
    "    grayscale=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred=cv2.GaussianBlur(grayscale,(5,5),0)\n",
    "    new_image= cv2.threshold(blurred, 100, 255, cv2.THRESH_BINARY,cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    if plot:\n",
    "        # plots the after before effect on the image based on parameter plot\n",
    "        # plot if plot=true, ignore the if block if plot=False\n",
    "        plt.figure()\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                        top=False,bottom=False,left=False,right=False,\n",
    "                       labelbottom=False,labeltop=False,labelleft=False,\n",
    "                       labelright=False)\n",
    "        plt.title(\"(a)\")\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(grayscale,cmap='gray')\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                        top=False,bottom=False,left=False,right=False,\n",
    "                       labelbottom=False,labeltop=False,labelleft=False,\n",
    "                       labelright=False)\n",
    "        plt.title(\"(b)\")\n",
    "        \n",
    "#         plt.subplot(1,4,3)\n",
    "#         plt.imshow(blurred,cmap='gray')\n",
    "#         plt.tick_params(axis=\"both\", which=\"both\",\n",
    "#                         top=False,bottom=False,left=False,right=False,\n",
    "#                        labelbottom=False,labeltop=False,labelleft=False,\n",
    "#                        labelright=False)\n",
    "#         plt.title(\"(c)\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         plt.subplot(1,4,4)\n",
    "#         plt.imshow(new_image,cmap=\"gray\")\n",
    "#         plt.tick_params(axis=\"both\", which=\"both\",\n",
    "#                         top=False,bottom=False,left=False,right=False,\n",
    "#                        labelbottom=False,labeltop=False,labelleft=False,\n",
    "#                        labelright=False)\n",
    "#         plt.title(\"(d)\")\n",
    "#         plt.show()\n",
    "        \n",
    "    return grayscale,new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the crop_contour_brain_img() function\n",
    "example_image=cv2.imread(path+\"/yes/3.jpg\")\n",
    "img=image_threshholder(example_image,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view directory tree\n",
    "def tree_printer(root):\n",
    "    try:\n",
    "        if \":\" not in root:\n",
    "            root=os.getcwd().replace(\"\\\\\",\"/\")+\"/\"+root\n",
    "            print(root)\n",
    "        if not os.path.isdir(root) and root!=\"\":\n",
    "            print(root,\": path not exists....\")\n",
    "            return\n",
    "    except:\n",
    "        print(\"🛠️ set path of the data set from your local mechine\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    print(\"🗁\",root,\"-->\",len(os.listdir(os.path.join(root))), \"Items present.\")\n",
    "    for name in os.listdir(root):\n",
    "        try:\n",
    "            print(\" |- 🗁\",name,\" \"*2+\"🏴\",len(os.listdir(os.path.join(root, name))),\"items\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "tree_printer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(64,64) # defining the image size \n",
    "hotencoder = OneHotEncoder() # calling the OneHotEncoder\n",
    "hotencoder.fit([[0], [1]]) # using binary crossentropy over catagorical crossentropy\n",
    "\n",
    "\n",
    "\n",
    "# load the images from the local mechine and process before putting the resultent list.\n",
    "def load_images(path,ishydro,type=[\"jpg\",\"jpeg\",\"png\"],org=[],orgimages=[],thrsl=[],target=[]):\n",
    "\n",
    "    for filepath in os.listdir(path):\n",
    "        if filepath.split(\".\")[-1].lower() in type:\n",
    "            \n",
    "            img=cv2.imread(path+\"/\"+filepath)\n",
    "               \n",
    "            \n",
    "            try:\n",
    "                # filtering the image\n",
    "                imgf,thrs=image_threshholder(img)\n",
    "                # resizing the image in defined size\n",
    "                imgf=cv2.resize(imgf,image_size)\n",
    "                thrs=cv2.resize(thrs,image_size)\n",
    "            except:\n",
    "                print(\"Excluded image :\",path+\"/\"+filepath)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # 3d image to 2D\n",
    "            imgf = np.expand_dims(imgf, 2)\n",
    "            orgimg=np.reshape(imgf,image_size)\n",
    "            \n",
    "            thrs = np.expand_dims(thrs, 2)\n",
    "            thrs=np.reshape(thrs,image_size)\n",
    "            \n",
    "            # pushing prepared data to list\n",
    "            if ishydro:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "            org.append(img)\n",
    "            orgimages.append(orgimg)\n",
    "            thrsl.append(thrs)\n",
    "            \n",
    "            \n",
    "    return [org,orgimages,thrsl,target]\n",
    "\n",
    "# plot images \n",
    "def show_image(datasets,num=4):  \n",
    "    plt.figure()\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    for i in range(num**2):\n",
    "        \n",
    "        plt.subplot(num, num, i+1)\n",
    "        plt.imshow(datasets[i],cmap=\"gray\")\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the image having brain cancer\n",
    "rawimages,orgimages,thrsimages,target=load_images(path+\"/yes\",True,org=[],orgimages=[],thrsl=[],target=[])\n",
    "img_index=list(range(len(target)))\n",
    "high_i=len(target)\n",
    "print(len(orgimages))\n",
    "show_image(orgimages,num=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawimages1,orgimages1,thrsimages1,target1=load_images(path+\"/no\",False,org=[],orgimages=[],thrsl=[],target=[])\n",
    "rawimages+=rawimages1\n",
    "orgimages+=orgimages1\n",
    "thrsimages+=thrsimages1\n",
    "target+=target1\n",
    "img_index+=list(range(high_i,len(target)))\n",
    "\n",
    "# # print(images.shape)\n",
    "show_image(orgimages[high_i:],num=3)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dimention of the processed data\n",
    "rawdata=np.array(rawimages)\n",
    "orgdata=np.array(orgimages)\n",
    "orgdata1=np.array(thrsimages)\n",
    "target=np.array(target)\n",
    "img_index=np.array(img_index)\n",
    "print(orgdata1.shape)\n",
    "# print(img_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom test-train splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized test train splitter\n",
    "\n",
    "def test_train_splitter(data,data1,train_ratio=0.2):\n",
    "    data,data1=shuffle(data,data1)\n",
    "    range=int(data.shape[0]*(1-train_ratio))\n",
    "    x_train=data[:range]\n",
    "    x_test_val=data[range:]\n",
    "    x_val=x_test_val[:(x_test_val.shape[0]//2)]\n",
    "    x_test=x_test_val[(x_test_val.shape[0]//2):]\n",
    "    \n",
    "    \n",
    "    x_train1=data1[:range]\n",
    "    x_test_val1=data1[range:]\n",
    "    x_val1=x_test_val1[:(x_test_val1.shape[0]//2)]\n",
    "    x_test1=x_test_val1[(x_test_val1.shape[0]//2):]\n",
    "    \n",
    "    return x_train,x_val,x_test,x_train1,x_val1,x_test1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model starts here -----------:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "# view explanation in 2nd cell\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder model func\n",
    "# encoder takes image(4096bit) input of size 64X64\n",
    "# encode the image in 64bit image(8X8)\n",
    "def get_encoder():\n",
    "    # Encoder input shape (4096,)\n",
    "    x = tensorflow.keras.layers.Input(shape=(64,64), name=\"encoder_input\")\n",
    "    \n",
    "    # flattening the data\n",
    "    flat_x=tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # scalling the data between 0..1\n",
    "#     scaled_x=tf.keras.layers.Rescaling(1./255)(flat_x)\n",
    "    \n",
    "    # neurons in a Dense layer is now 2048 \n",
    "    encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=2048, name=\"encoder_dense_1\")(flat_x)\n",
    "    encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
    "\n",
    "    # neurons in a Dense layer is decreased to 1024\n",
    "    encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=1024, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
    "    encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 512\n",
    "    encoder_dense_layer3 = tensorflow.keras.layers.Dense(units=512, name=\"encoder_dense_3\")(encoder_activ_layer2)\n",
    "    encoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(encoder_dense_layer3)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 256\n",
    "    encoder_dense_layer4 = tensorflow.keras.layers.Dense(units=256, name=\"encoder_dense_4\")(encoder_activ_layer3)\n",
    "    encoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_4\")(encoder_dense_layer4)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 64\n",
    "    encoder_dense_layer5 = tensorflow.keras.layers.Dense(units=64, name=\"encoder_dense_5\")(encoder_activ_layer4)\n",
    "    encoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_output\")(encoder_dense_layer5)\n",
    "\n",
    "    # containerized the model\n",
    "    encoder = tensorflow.keras.models.Model(x, encoder_activ_layer5, name=\"encoder_model\")\n",
    "    return encoder\n",
    "\n",
    "encoder=get_encoder()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decoder model func\n",
    "# encode the encoded image(64bit) back to original size(4096 bit).\n",
    "\n",
    "def get_decoder():\n",
    "    decoder_input = tensorflow.keras.layers.Input(shape=(64), name=\"decoder_input\")\n",
    "\n",
    "    # neurons in a Dense layer is now 256\n",
    "    decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=256, name=\"encoder_dense_1\")(decoder_input)\n",
    "    decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
    "\n",
    "    # neurons in a Dense layer is decreased to 512\n",
    "    decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=512, name=\"encoder_dense_2\")(decoder_activ_layer1)\n",
    "    decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 1024\n",
    "    decoder_dense_layer3 = tensorflow.keras.layers.Dense(units=1024, name=\"encoder_dense_3\")(decoder_activ_layer2)\n",
    "    decoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_dense_layer3)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 2048\n",
    "    decoder_dense_layer4 = tensorflow.keras.layers.Dense(units=2048, name=\"encoder_dense_4\")(decoder_activ_layer3)\n",
    "    decoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_4\")(decoder_dense_layer4)\n",
    "    \n",
    "    # neurons in a Dense layer is decreased to 4096\n",
    "    decoder_dense_layer5 = tensorflow.keras.layers.Dense(units=4096, name=\"decoder_dense_5\")(decoder_activ_layer4)\n",
    "    decoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_dense_layer5)\n",
    "    \n",
    "    # reshaped the image to 64X64\n",
    "    decoder_output=tf.keras.layers.Reshape((64,64), input_shape=(4096,))(decoder_activ_layer5)\n",
    "    \n",
    "    decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "decoder=get_decoder()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "# combine and sync the encoder and decoder model.\n",
    "# parameter encoder model and decoder model.\n",
    "\n",
    "def autoencoder(encoder,decoder):\n",
    "    ae_input = tensorflow.keras.layers.Input(shape=(64,64), name=\"AE_input\")\n",
    "    \n",
    "    # encoding the input images\n",
    "    ae_encoder_output = encoder(ae_input)\n",
    "    # decoding the encoded image back to original shape\n",
    "    ae_decoder_output = decoder(ae_encoder_output)\n",
    "\n",
    "    \n",
    "    \n",
    "    ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
    "    return ae\n",
    "\n",
    "\n",
    "ae=autoencoder(encoder,decoder)\n",
    "ae.summary()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating RMSE of autoencoder\n",
    "# RMSE is a measure of how spread out these residuals are. \n",
    "# It tells you how concentrated the data is around the line of best fit. \n",
    "def rmse(y_true, y_predict):\n",
    "    return tensorflow.keras.backend.mean(tensorflow.keras.backend.square(y_true-y_predict))\n",
    "\n",
    "# AE Compilation\n",
    "ae.compile(loss=\"mse\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing brain tumor dataset spliting into test train default ratio is 0.2\n",
    "\n",
    "x_train_index,x_val_index,x_test_index,x_train_org1,x_val_org1,x_test_org1=test_train_splitter(img_index,orgdata1)\n",
    "\n",
    "print(x_train_index.shape,x_val_index.shape,x_test_index.shape)\n",
    "print(x_train_org1.shape,x_val_org1.shape,x_test_org1.shape)\n",
    "# print(x_test_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Training Autoencoder\n",
    "ae.fit(x_train_org1, x_train_org1, epochs=20, batch_size=10, shuffle=True,validation_data=(x_val_org1, x_val_org1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "encoded_images = encoder.predict(x_test_org1)\n",
    "encode_time=time.time() - start_time\n",
    "decoded_images = decoder.predict(encoded_images)\n",
    "# calculating execution time\n",
    "execution_time=time.time() - start_time\n",
    "decode_time=execution_time-encode_time\n",
    "\n",
    "x_test_org=np.array([orgdata[i] for i in x_test_index])\n",
    "\n",
    "# decoder original image resolution\n",
    "org_res=(decoded_images.shape[0], 64, 64)\n",
    "\n",
    "encoded_samples=np.reshape(encoded_images, newshape=(decoded_images.shape[0], 8, 8))\n",
    "\n",
    "# reshaping the image of (4096,) to plotable image(64,64)\n",
    "decoded_images_orig = np.reshape(decoded_images, newshape=org_res)\n",
    "decoded_images_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating RMSE of the trained model\n",
    "rmse_ae=rmse(x_test_org,decoded_images)\n",
    "print(rmse_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"encoder image shape\",encoded_images[0].shape)\n",
    "print(\"decoder image shape\",decoded_images[0].shape)\n",
    "\n",
    "# ploting the comparition between original,encoded and decoded image.\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.subplot(1,3,1)\n",
    "sample_id=1\n",
    "global_index=x_test_index[sample_id]\n",
    "\n",
    "original_sample=x_test_org[sample_id]\n",
    "plt.imshow(original_sample,cmap=\"gray\")\n",
    "plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "plt.title(\"original image\")\n",
    "        \n",
    "plt.subplot(1,3,2)\n",
    "\n",
    "encoded_sample = encoded_samples[sample_id]\n",
    "plt.imshow(encoded_sample,cmap=\"gray\")\n",
    "plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "plt.title(\"encoded image\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "decoded_sample=decoded_images_orig[sample_id]\n",
    "plt.imshow(decoded_sample,cmap=\"gray\")\n",
    "plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "plt.title(\"decoded image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance parameter\n",
    "1. execution time\n",
    "2. compression ratio\n",
    "3. space saving\n",
    "4. Bits per pixel (BPP)\n",
    "5. Mean squared error (MSE)\n",
    "6. Structure Similarity Index (SSIM)\n",
    "7. Peak Signal to Noise Ratio (PSNR)\n",
    "8. Percent rate of distortion (PRD)\n",
    "9. Structural Content (SC)\n",
    "10. Correlation Coefficient (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg execution time=total execution time/no of testing sample\n",
    "print(\"Total execution time = {} seconds\".format(execution_time))\n",
    "print(\"Avarage Execution time = {} MilliSeconds\".format(execution_time/encoded_images.shape[0]*1000))\n",
    "\n",
    "print(\"Total encoding time = {} seconds\".format(encode_time))\n",
    "print(\"Avarage Encoding time = {} MilliSeconds\".format(encode_time/encoded_images.shape[0]*1000))\n",
    "\n",
    "print(\"Total decode Time = {} seconds\".format(decode_time))\n",
    "print(\"Avarage Decoding time = {} MilliSeconds\".format(decode_time/encoded_images.shape[0]*1000))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def performance_param_generator(encoded_sample,original_sample,imgnum=\"test\"):\n",
    "    if os.path.isdir(r\"static\"):\n",
    "        for file in os.listdir(r'static'):\n",
    "            if file.endswith('.jpg'):\n",
    "                try:\n",
    "                    os.remove(file)\n",
    "                except:\n",
    "                    pass\n",
    "    else:\n",
    "        os.system(\"mkdir static\")\n",
    "    \n",
    "    # convert 2D image to 3D\n",
    "    orgToSave=cv2.cvtColor(original_sample, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # saving the image .jpg format.\n",
    "    cv2.imwrite('static/comp_sample_'+str(imgnum)+'.jpg',encoded_sample)\n",
    "    cv2.imwrite('static/org_sample_'+str(imgnum)+'.jpg',orgToSave)\n",
    "    \n",
    "    # getting the size of the image\n",
    "    size_bytes_comp = os.path.getsize('static/comp_sample_'+str(imgnum)+'.jpg')\n",
    "    size_bytes_org = os.path.getsize('static/org_sample_'+str(imgnum)+'.jpg')\n",
    "    \n",
    "    # number of pixel in compressed image for image sample 0\n",
    "    comp_pixel=encoded_sample.shape[0]\n",
    "    \n",
    "    # converting the bytes to bit by multiplying by 8\n",
    "    size_bits_comp=size_bytes_comp*8\n",
    "    size_bits_org=size_bytes_org*8\n",
    "\n",
    "    # Bits Per Pixel (BPP): BPP is defined as the ratio of the total size of the compressed image to the total number \n",
    "    # of the pixel in the image.\n",
    "    BPP=size_bits_comp/comp_pixel\n",
    "\n",
    "\n",
    "    # compression_ratio = orizinal image size / compressed image size\n",
    "    compression_ratio=round(size_bits_org / size_bits_comp,3)\n",
    "\n",
    "\n",
    "    # defined as the reduction in size relative to the uncompressed size:\n",
    "    space_saving=round(1-(1/compression_ratio),2)\n",
    "\n",
    "    \n",
    "    return compression_ratio,BPP,space_saving,size_bits_comp,size_bits_org\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error (MSE): MSE is the description of the cumulative squared error between the \n",
    "# compressed image and the original image\n",
    "def MSE(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    \n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])*1000\n",
    "    return round(err,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return round(psnr,3)\n",
    "\n",
    "\n",
    "\n",
    "def PRD(original,decoded):\n",
    "    sum_diff=np.sum((original - decoded))**2\n",
    "    sum_org=np.sum(original)**2\n",
    "    prd=sqrt(sum_diff/sum_org)*100\n",
    "    return round(prd,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SC(original,decoded):\n",
    "    sum_org=np.sum(original**2)\n",
    "    sum_dec=np.sum(decoded**2)\n",
    "    sc=sum_org/sum_dec\n",
    "    return round(sc,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def correlation_coeff(orgimage, decoded):\n",
    "    cc = (np.sum(orgimage*decoded))/ ((sqrt((np.sum(orgimage)**2)) * (sqrt((np.sum(decoded)**2)))))\n",
    "    return round(cc,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_ratio,BPP,space_saving,size_bits_comp,size_bits_org=performance_param_generator(encoded_sample,original_sample)\n",
    "\n",
    "print(\"File size of Compressed image :\",size_bits_comp,\"bits\")\n",
    "print(\"File size of Original image :\",size_bits_org,\"bits\")\n",
    "print(\"BPP for sample image :\",BPP,\"bits/pixel\")\n",
    "print(\"Compression ratio :\", comp_ratio)\n",
    "print(\"Space saving :\",space_saving)\n",
    "\n",
    "# calculating MSE of original and decompressed image\n",
    "print(\"Mean Squared Error of original and decompressed image :\",MSE(original_sample,decoded_sample))\n",
    "\n",
    "\n",
    "# calculating SSIM of original and decompressed image\n",
    "\n",
    "# Structure Similarity Index (SSIM): SSIM is used to measure the tendency of similarity between the \n",
    "# original image and the compressed image\n",
    "print(\"Structure Similarity Index(SSIM) of original and decompressed image :\",round(SSIM(original_sample,decoded_sample),3))\n",
    "\n",
    "# Peak Signal to Noise Ratio (PSNR): PSNR is defined as the ratio of the maximum pixel intensity to the \n",
    "# mean square error\n",
    "print(\"Peak Signal to Noise Ratio (PSNR) of original and decompressed image :\",PSNR(original_sample,decoded_sample))\n",
    "\n",
    "print(\"PRD of original and decompressed image :\",PRD(original_sample,decoded_sample),\"%\")\n",
    "\n",
    "print(\"Structural content of original and decompressed image :\",SC(original_sample,decoded_sample))\n",
    "\n",
    "print(\"Correlation Coefficient (CC) of original and decompressed image :\",correlation_coeff(original_sample,decoded_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_monitor(x_test_org,encoded_samples,decoded_images_orig,rawdata,x_test_index,num_images_to_show = 5):\n",
    "    # comparing some more images between original and decode image.\n",
    "    performance=[]\n",
    "    \n",
    "    if num_images_to_show==-1 or num_images_to_show>=x_test_org.shape[0]:\n",
    "        num_images_to_show=x_test_org.shape[0]\n",
    "        \n",
    "#     suffled_index=random.sample(range(0,x_test_org.shape[0]), num_images_to_show)\n",
    "    \n",
    "    columns =['Id','target', 'encoded image size (bits)', 'original image size (bits)',\"compression ratio\",\"BPP\",\"space saving\",\"MSE\",\"SSIM\",\"PSNR\",\"PRD\",\"SC\",\"CC\"]\n",
    "    font=14\n",
    "    for rand_ind,_ in enumerate(x_test_org):\n",
    "        plot_ind = rand_ind*5 + 1\n",
    "        original_sample=x_test_org[rand_ind]\n",
    "        \n",
    "        plt.figure(figsize=(10, round(num_images_to_show*2)))\n",
    "        \n",
    "        plt.subplot(num_images_to_show, 5, plot_ind)\n",
    "        plt.imshow(rawdata[x_test_index[rand_ind]], cmap=\"gray\")\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "        if rand_ind==0:\n",
    "            plt.title(\"Original\",fontsize=font)\n",
    "        \n",
    "        plt.subplot(num_images_to_show, 5, plot_ind+1)\n",
    "        plt.imshow(original_sample, cmap=\"gray\")\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "        if rand_ind==0:\n",
    "            plt.title(\"Grayscaled\",fontsize=font)\n",
    "        \n",
    "        \n",
    "        plt.subplot(num_images_to_show, 5, plot_ind+2)\n",
    "        plt.imshow(original_sample, cmap=\"gray\")\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "        if rand_ind==0:\n",
    "            plt.title(\"Resized\",fontsize=font)\n",
    "        \n",
    "        \n",
    "        plt.subplot(num_images_to_show, 5, plot_ind+3)\n",
    "        encoded_sample = encoded_samples[rand_ind]\n",
    "        plt.imshow(encoded_sample, cmap=\"gray\")\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "        if rand_ind==0:\n",
    "            plt.title(\"Encoded\",fontsize=font)\n",
    "        \n",
    "        \n",
    "        \n",
    "        decoded_sample=decoded_images_orig[rand_ind]\n",
    "        # Clipping data to the valid range for imshow with RGB data ([0..1]\n",
    "        plt.subplot(num_images_to_show, 5, plot_ind+4)\n",
    "        plt.imshow(decoded_sample,cmap=\"gray\")\n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                top=False,bottom=False,left=False,right=False,\n",
    "                labelbottom=False,labeltop=False,labelleft=False,\n",
    "                labelright=False)\n",
    "        if rand_ind==0:\n",
    "            plt.title(\"Decoded\",fontsize=font)\n",
    "        \n",
    "        \n",
    "        comp_ratio,BPP,space_saving,size_bits_comp,size_bits_org=performance_param_generator(encoded_sample,original_sample,rand_ind)\n",
    "        mse=MSE(original_sample,decoded_sample)\n",
    "        ssim=round(SSIM(original_sample,decoded_sample),3)\n",
    "        psnr=PSNR(original_sample,decoded_sample)\n",
    "        prd=PRD(original_sample,decoded_sample)\n",
    "        sc=SC(original_sample,decoded_sample)\n",
    "        cc=correlation_coeff(original_sample,decoded_sample)\n",
    "         \n",
    "    \n",
    "        performance.append([x_test_index[rand_ind],target[x_test_index[rand_ind]],size_bits_comp,size_bits_org,comp_ratio,BPP,space_saving,mse,ssim,psnr,prd,sc,cc])\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(encoded_images[:, 0], encoded_images[:, 1])\n",
    "    plt.colorbar()\n",
    "    table=pd.DataFrame(performance, columns=columns)\n",
    "    table.set_index('Id',inplace=True)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_images_to_show=-1\n",
    "table=performance_monitor(x_test_org,encoded_samples,decoded_images_orig,rawdata,x_test_index,num_images_to_show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liOfCR=table['compression ratio'].tolist()\n",
    "avg_CR=sum(liOfCR)/len(liOfCR)\n",
    "print(\"Average Compression Ratio is\",avg_CR)\n",
    "print(\"Minimum Compression Ratio is\",min(liOfCR))\n",
    "print(\"Maximum Compression Ratio is\",max(liOfCR))\n",
    "table.head(num_images_to_show)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath,type=[\"jpg\",\"jpeg\",\"png\"],orgimages=[],thrsl=[],rawimages=[]):\n",
    "    if filepath.split(\".\")[-1].lower() in type:\n",
    "\n",
    "        img=cv2.imread(filepath)\n",
    "        rawimages.append(img)\n",
    "\n",
    "        try:\n",
    "            # filtering the image\n",
    "            img,thrs=image_threshholder(img)\n",
    "            # resizing the image in defined size\n",
    "            img=cv2.resize(img,image_size)\n",
    "            thrs=cv2.resize(thrs,image_size)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Excluded image :\",filepath)\n",
    "            \n",
    "\n",
    "\n",
    "        # 3d image to 2D\n",
    "        img = np.expand_dims(img, 2)\n",
    "        orgimg=np.reshape(img,image_size)\n",
    "\n",
    "        thrs = np.expand_dims(thrs, 2)\n",
    "        thrs=np.reshape(thrs,image_size)\n",
    "\n",
    "        # pushing prepared data to list\n",
    "        orgimages.append(orgimg)\n",
    "        thrsl.append(thrs)\n",
    "            \n",
    "            \n",
    "    return [orgimages,thrsl,rawimages]\n",
    "\n",
    "def pred_loose_img(img_relative_path=None,folder=None):\n",
    "    orgimages_new=[]\n",
    "    thrsimages_new=[]\n",
    "    rawdata_new=[]\n",
    "    if folder!=None:\n",
    "        for file in os.listdir(path+folder):\n",
    "            if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n",
    "                orgimages1,thrsimages1,rawdata1=load_image(path+folder+file,orgimages=[],thrsl=[],rawimages=[])\n",
    "                orgimages_new+=orgimages1\n",
    "                thrsimages_new+=thrsimages1\n",
    "                rawdata_new+=rawdata1\n",
    "#                 print(file)\n",
    "    \n",
    "    else:\n",
    "        orgimages_new,thrsimages_new,rawdata_new=load_image(path+img_relative_path,orgimages=[],thrsl=[])\n",
    "        \n",
    "    orgdata_new=np.array(orgimages_new)\n",
    "    orgdata1_new=np.array(thrsimages_new)\n",
    "    rawdata_new=np.array(rawdata_new)\n",
    "\n",
    "\n",
    "\n",
    "    encoded_image_s = encoder.predict(orgdata1_new)\n",
    "\n",
    "    decoded_image_s = decoder.predict(encoded_image_s)\n",
    "#     print(decoded_image_s.shape)\n",
    "\n",
    "\n",
    "    # decoder original image resolution\n",
    "    org_res=(decoded_image_s.shape[0], 64, 64)\n",
    "\n",
    "    encoded_samples_s=np.reshape(encoded_image_s, newshape=(decoded_image_s.shape[0], 8, 8))\n",
    "\n",
    "    # reshaping the image of (4096,) to plotable image(64,64)\n",
    "    decoded_images_orig_s = np.reshape(decoded_image_s, newshape=org_res)\n",
    "    x_test_index_s=np.array(list(range(decoded_image_s.shape[0])))\n",
    "#     print(x_test_index_s)\n",
    "    table=performance_monitor(orgdata_new,encoded_samples_s,decoded_images_orig_s,rawdata_new,x_test_index_s,-1)\n",
    "    liOfCR=table['compression ratio'].tolist()\n",
    "    avg_CR=sum(liOfCR)/len(liOfCR)\n",
    "    print(\"Average Compression Ratio is\",avg_CR)\n",
    "    print(\"Minimum Compression Ratio is\",min(liOfCR))\n",
    "    print(\"Maximum Compression Ratio is\",max(liOfCR))\n",
    "    table.head()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loose_img(folder=r\"/special_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loose_img(img_relative_path=r\"/yes/10.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison graph of various method based on performance parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_generator(data,color=\"black\",marker=\"o\"):\n",
    "    ax=plt.subplot()\n",
    "    ax.plot(data[\"method\"], data[\"value\"], color=color, marker=marker)\n",
    "#     plt.title(data[\"Title\"], fontsize=14)\n",
    "    plt.xlabel(data[\"x_title\"], fontsize=14)\n",
    "    plt.ylabel(data[\"y_title\"], fontsize=14)\n",
    "    for i, v in enumerate(data[\"value\"]):\n",
    "        ax.annotate(str(v), xy=(i,v), xytext=(-7,7), textcoords='offset points')\n",
    "#     plt.legend(handles=data[\"method\"])\n",
    "#     ax.grid(False)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "    plt.ylim(min(data[\"value\"])-1, max(data[\"value\"])+2)\n",
    "    plt.xlim(-1,7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression ratio graph\n",
    "cr_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[6.319,4.203,3.664,3.576,3.982,4.205,9.422],\n",
    "    \"y_title\":\"Compression ratio\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on compression ratio\"\n",
    "}\n",
    "\n",
    "\n",
    "psnr_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[10.321,11.235,9.420,10.505,8.663,12.935,16.750],\n",
    "    \"y_title\":\"Peak Signal to Noise Ratio\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on PSNR\"\n",
    "}\n",
    "\n",
    "snr_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[16.7,18.1,17.7,17.0,16.5,17.2,18.6],\n",
    "    \"y_title\":\"Signal to Noise Ratio\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on SNR\"\n",
    "}\n",
    "\n",
    "ssi_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[0.092,0.157,0.296,0.350,0.199,0.236,0.070],\n",
    "    \"y_title\":\"Structure Similarity Index\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on SSI\"\n",
    "}\n",
    "\n",
    "mse_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[5.250,4.117,6.996,3.507,4.526,6.001,3.166],\n",
    "    \"y_title\":\"Mean Squred Error\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on MSE\"\n",
    "}\n",
    "\n",
    "rmse_graph={\n",
    "    \"method\":[\"LZW\",\"Huffman coding\",\"EZW\",\"RLE\",\"Shannon-Fano\",\"Arithmetic coding\",\"Proposed method\"],\n",
    "    \"value\":[2.291, 2.029, 2.645, 1.873, 2.127, 2.45, 1.779],\n",
    "    \"y_title\":\"Root Mean Squred Error\",\n",
    "    \"x_title\":\"Method names\",\n",
    "    \"Title\":\"Comparison graph of various method based on RMSE\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_generator(cr_graph)\n",
    "graph_generator(mse_graph,\"red\")\n",
    "graph_generator(rmse_graph,\"orange\")\n",
    "graph_generator(ssi_graph,\"blue\")\n",
    "graph_generator(psnr_graph,\"green\")\n",
    "graph_generator(snr_graph,\"cyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !explorer .\n",
    "# 70 train\n",
    "# 15 validation \n",
    "# 15 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[5.250,4.117,6.996,3.507,4.526,6.001,3.166]\n",
    "for i in range(7):\n",
    "    a[i]=round(sqrt(a[i]),3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:right;\">Developed by: Tirtharaj Sinha</h4>\n",
    "<h5 style=\"text-align:right;\">github repository : <a href=\"https://github.com/tirtharajsinha/Autoencoder_for_image_compression\">@tirtharajsinha/Autoencoder_for_image_compression</a></h5>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
